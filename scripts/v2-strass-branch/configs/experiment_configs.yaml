# config/experiment_configs.yaml
experiments:
  baseline:
    classifiers:
      # OLS
      - type: "linear_regression"  
        config:
          fit_intercept: true  # Whether to calculate intercept
          normalize: true     # False = Don't use ? - prefer preprocessing standardization
          standardize: true     # Critical for OLS
          #copy_X: true         # Copy or overwrite input data
          #n_jobs: -1           # Parallel processing - use all cores (?)
          positive: false      # Force positive coefficients
          data:
        #modalities: ["fmri", "behavioral"]  # Your modalities
        #preprocessing:
        #standardize: true        # Critical for OLS
      #feature_selection: false # Start simple
      #model:
        #type: "ols"
        #config:
          #fit_intercept: true      # Always include intercept
          #copy_X: true             # Safer memory handling
      #evaluation:
        #metrics: 
          #regression: ["mse", "r2"]
          #classification: ["accuracy", "roc_auc"] 
        #cross_validation:
          #folds: 5
          #shuffle: true
      - type: "svm"
        config:
          C: 1.0
          kernel: "rbf"
          gamma: "scale"
      - type: "mlp"
        config:
          hidden_dims: [512, 256, 128]
          dropout_rate: 0.3
          learning_rate: 0.001
          batch_size: 32
      - type: "random_forest"
        config:
          n_estimators: 100
          max_depth: 10
          random_state: 42
      - type: "logistic_regression"
        config:
          C: 1.0
          max_iter: 1000
          random_state: 42
      - type: "self_attention"
        config:
          d_model: 256
          n_heads: 8
          n_layers: 6
          d_ff: 1024
          dropout_rate: 0.1
          learning_rate: 0.0001
          n_epochs: 150
          batch_size: 16
          max_seq_len: 1000
      - type: "mlp"
        config:
          hidden_dims: [512, 256, 128]
          dropout_rate: 0.3
          learning_rate: 0.001
          n_epochs: 100
          batch_size: 32
          weight_decay: 0.0001
    
  neural_networks:
    classifiers:
      - type: "mlp"
        config:
          hidden_dims: [512, 256, 128]
          dropout_rate: 0.3
          learning_rate: 0.001
          n_epochs: 100
          batch_size: 32
      - type: "cnn"
        config:
          n_filters: [64, 128, 256]
          kernel_size: 3
          dropout_rate: 0.5
          learning_rate: 0.001
          n_epochs: 100
    
  advanced:
    classifiers:
      - type: "transformer"
        config:
          d_model: 256
          nhead: 8
          num_layers: 6
          dropout_rate: 0.1
          learning_rate: 0.0001
          n_epochs: 150

data:
  data_path: "data/raw"
  preprocessed_path: "data/preprocessed"
  test_size: 0.2
  random_state: 42
  
preprocessing:
  standardize: true
  dimensionality_reduction:
    method: "pca"  # or "ica", "umap", "none"
    n_components: 1000
  
cross_validation:
  n_folds: 5
  shuffle: true
  random_state: 42